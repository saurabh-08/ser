{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ExNRUKKR6YwH"
   },
   "source": [
    "#Stage 1 - Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10625,
     "status": "ok",
     "timestamp": 1586674223176,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "Ea0hqj66690K",
    "outputId": "31bd8bc6-65aa-4d78-9f5b-f2e8cc4a4be4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#%tensorflow_version 1.4 \n",
    "\n",
    "## Package\n",
    "import glob \n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.offline as py\n",
    "#import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import scipy.io.wavfile\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#py.init_notebook_mode(connected=True)\n",
    "\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 467363,
     "status": "ok",
     "timestamp": 1586674679930,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "6FbU3MiE7HaA",
    "outputId": "68037b87-6136-4948-91ab-231d04317c5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Actor_01', 'Actor_02', 'Actor_03', 'Actor_04', 'Actor_05', 'Actor_06', 'Actor_07', 'Actor_08', 'Actor_09', 'Actor_10', 'Actor_11', 'Actor_12', 'Actor_13', 'Actor_14', 'Actor_15', 'Actor_16', 'Actor_17', 'Actor_18', 'Actor_19', 'Actor_20', 'Actor_21', 'Actor_22', 'Actor_23', 'Actor_24']\n"
     ]
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Read list of audio files from the source directory\n",
    "source_dir_list = os.listdir('/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set')\n",
    "source_dir_list.sort()\n",
    "source_dir_list = source_dir_list[1:]\n",
    "print (source_dir_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gcSx-7lF88mn"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set.ipynb_checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9878ab245aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_dir_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfile_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set.ipynb_checkpoints'"
     ]
    }
   ],
   "source": [
    "audio_data = pd.DataFrame(columns=['path', 'source', 'actor', 'gender',\n",
    "                                'intensity', 'statement', 'repetition', 'emotion'])\n",
    "count = 0\n",
    "for directory in source_dir_list:\n",
    "    file_list = os.listdir('/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set' + directory)\n",
    "    for files in file_list:\n",
    "        name = files.split('.')[0].split('-')\n",
    "        path = '/Users/saurabh/Downloads/Emotion_Detection 2/sed_data_set' + directory + '/' + files\n",
    "        src = int(name[1])\n",
    "        actor = int(name[-1])\n",
    "        emotion = int(name[2])\n",
    "        \n",
    "        if int(actor)%2 == 0:\n",
    "            gender = \"female\"\n",
    "        else:\n",
    "            gender = \"male\"\n",
    "        \n",
    "        if name[3] == '01':\n",
    "            intensity = 0\n",
    "        else:\n",
    "            intensity = 1\n",
    "        \n",
    "        if name[4] == '01':\n",
    "            statement = 0\n",
    "        else:\n",
    "            statement = 1\n",
    "        \n",
    "        if name[5] == '01':\n",
    "            repeat = 0\n",
    "        else:\n",
    "            repeat = 1\n",
    "            \n",
    "        audio_data.loc[count] = [path, src, actor, gender, intensity, statement, repeat, emotion]\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 475774,
     "status": "ok",
     "timestamp": 1586674688381,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "F3eA-e9A99e4",
    "outputId": "9b2edaa2-e9e4-47a6-8491-dedd54c7c286"
   },
   "outputs": [],
   "source": [
    "print (len(audio_data)) #Total number of audio files \n",
    "audio_data.head() #About the audio files in the source directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ywjzPNPe_brI"
   },
   "source": [
    "#Stage 2 - Plotting a random audio file's waveform and its spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479477,
     "status": "ok",
     "timestamp": 1586674692097,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "GZlYbjjA_pwZ",
    "outputId": "f234bf97-8226-4129-d462-59ea76514063"
   },
   "outputs": [],
   "source": [
    "filename = audio_data.path[random.randint(0,len(audio_data)-1)]\n",
    "print (filename)\n",
    "\n",
    "samples, sample_rate = librosa.load(filename)\n",
    "sample_rate, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479456,
     "status": "ok",
     "timestamp": 1586674692100,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "Fdpv-0TXBtG-",
    "outputId": "98328435-b890-4f28-dcac-bd220cfa0c59"
   },
   "outputs": [],
   "source": [
    "len(samples), sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XGl7wDYTB2ha"
   },
   "outputs": [],
   "source": [
    "# Define Log Specgram function to generate frequency, times and spectrogram from the audio file\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479444,
     "status": "ok",
     "timestamp": 1586674692102,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "2rW6Sy4HCYri",
    "outputId": "1544bfe2-7613-4f79-ee70-cae50feb36cf"
   },
   "outputs": [],
   "source": [
    "freqs, times, spectrogram = log_specgram(samples, sample_rate)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "fig1 = fig.add_subplot(211)\n",
    "fig1.set_title('Raw wave of ' + filename)\n",
    "fig1.set_ylabel('Amplitude')\n",
    "librosa.display.waveplot(samples, sr=sample_rate)\n",
    "\n",
    "fig2 = fig.add_subplot(212)\n",
    "fig2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "           extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "fig2.set_yticks(freqs[::16])\n",
    "fig2.set_xticks(times[::16])\n",
    "fig2.set_title('Spectrogram of ' + filename)\n",
    "fig2.set_ylabel('Freqs in Hz')\n",
    "fig2.set_xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480787,
     "status": "ok",
     "timestamp": 1586674693453,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "IKXFbhceEiLJ",
    "outputId": "bed85d3e-0d47-4da7-9153-4779f3b4169d"
   },
   "outputs": [],
   "source": [
    "#Trim silence part of the audio file\n",
    "aa , bb = librosa.effects.trim(samples, top_db=30)\n",
    "aa, bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480776,
     "status": "ok",
     "timestamp": 1586674693454,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "n7cm74_XFLsP",
    "outputId": "8aa93e36-1d9a-4c76-fbee-608464304391"
   },
   "outputs": [],
   "source": [
    "# Plotting Mel Power Spectrogram\n",
    "S = librosa.feature.melspectrogram(aa, sr=sample_rate, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(log_S, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "plt.title('Mel power spectrogram ')\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480767,
     "status": "ok",
     "timestamp": 1586674693455,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "LArIMfYzFifG",
    "outputId": "716a8481-d54e-4feb-fa44-ab94c8d6a56a"
   },
   "outputs": [],
   "source": [
    "# Plotting MFCC\n",
    "mfcc = librosa.feature.mfcc(S=log_S, n_mfcc=13)\n",
    "\n",
    "#Second order differentiation of the Mel spectrogram\n",
    "delta2_mfcc = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(delta2_mfcc)\n",
    "plt.ylabel('MFCC coeffs')\n",
    "plt.xlabel('Time')\n",
    "plt.title('MFCC')\n",
    "plt.colorbar()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480758,
     "status": "ok",
     "timestamp": 1586674693456,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "WZwdb0_pGCxs",
    "outputId": "58ea95c0-c15d-4503-cb10-018d7ff94d0d"
   },
   "outputs": [],
   "source": [
    "# Silence Trimmed Sample Audio \n",
    "ipd.Audio(aa, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnVcpvYAHhw3"
   },
   "source": [
    "#Stage 3- Define the Output classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480750,
     "status": "ok",
     "timestamp": 1586674693457,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "nJUx8THCIKpZ",
    "outputId": "71115bac-2e1e-4958-defe-c336f4a6f992"
   },
   "outputs": [],
   "source": [
    "label_list = []\n",
    "\n",
    "for i in range(len(audio_data)):\n",
    "    if audio_data.emotion[i] == 1:\n",
    "        lb = \"_neutral\"\n",
    "    elif audio_data.emotion[i] == 2:\n",
    "        lb = \"_calm\"\n",
    "    elif audio_data.emotion[i] == 3:\n",
    "        lb = \"_happy\"\n",
    "    elif audio_data.emotion[i] == 4:\n",
    "        lb = \"_sad\"\n",
    "    elif audio_data.emotion[i] == 5:\n",
    "        lb = \"_angry\"\n",
    "    elif audio_data.emotion[i] == 6:\n",
    "        lb = \"_fearful\"\n",
    "    elif audio_data.emotion[i] == 7:\n",
    "        lb = \"_disgust\"\n",
    "    elif audio_data.emotion[i] == 8:\n",
    "        lb = \"_surprised\"\n",
    "    else:\n",
    "        lb = \"_none\"\n",
    "        \n",
    "    # Add gender to the label \n",
    "    label_list.append(audio_data.gender[i]  + lb)\n",
    "\n",
    "#Append the labels to audio data\n",
    "\n",
    "audio_data['label'] = label_list\n",
    "audio_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RL0sEseaKev9"
   },
   "source": [
    "#Stage 4 - Extracting features of all audio files using librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422507,
     "status": "ok",
     "timestamp": 1586675635223,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "PqL5beJ7LM-R",
    "outputId": "ba4a29e8-3f23-4886-cdf3-748961a160f1"
   },
   "outputs": [],
   "source": [
    "#Extract the features using MFCC\n",
    "data = pd.DataFrame(columns=['feature'])\n",
    "for i in tqdm(range(len(audio_data))):\n",
    "\n",
    "    X, sample_rate = librosa.load(audio_data.path[i], res_type='kaiser_fast',duration=3,sr=22050*2,offset=0.5)\n",
    "    sample_rate = np.array(sample_rate)\n",
    "    pure_X , bb = librosa.effects.trim(X, top_db=30)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=pure_X, sr=sample_rate, n_mfcc=13), axis=0)\n",
    "    feature = mfccs\n",
    "    data.loc[i] = [feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422502,
     "status": "ok",
     "timestamp": 1586675635228,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "fB7_waCBTI6B",
    "outputId": "b30f1840-4d5f-4c0b-867a-f39512d85a2c"
   },
   "outputs": [],
   "source": [
    "# Display features of first 5 Audio Files \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422494,
     "status": "ok",
     "timestamp": 1586675635229,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "SCYc4NgqTueF",
    "outputId": "954aae97-f06e-4c15-a84d-ad5c045fa64a"
   },
   "outputs": [],
   "source": [
    "# Covert features into a DataFrame and label them accordingly\n",
    "\n",
    "feature_data = pd.DataFrame(data['feature'].values.tolist())\n",
    "labels = audio_data.label\n",
    "\n",
    "labeled_data = pd.concat([feature_data,labels],axis=1)\n",
    "\n",
    "new_labeled_data = labeled_data.rename(index=str, columns={\"0\": \"label\"})\n",
    "\n",
    "new_labeled_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1422485,
     "status": "ok",
     "timestamp": 1586675635230,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "2JhTyfITU4_K",
    "outputId": "6cb340a0-9ba0-4cc7-8ddb-b4b6886ffbf1"
   },
   "outputs": [],
   "source": [
    "# Replace null values with 0\n",
    "\n",
    "print(new_labeled_data.isnull().sum().sum())\n",
    "\n",
    "new_labeled_data = labeled_data.fillna(0)\n",
    "new_labeled_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PCSej3UuVlTN"
   },
   "source": [
    "#Plot Emotion Distribution of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423063,
     "status": "ok",
     "timestamp": 1586675635819,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "ShTShNSxVsun",
    "outputId": "dd237289-e625-48c3-f212-f4bf058125f3"
   },
   "outputs": [],
   "source": [
    "#Plot the graph of total number of audio files based on its emotional class \n",
    "\n",
    "tmp_data = pd.DataFrame()\n",
    "tmp_data['Emotion'] = list(audio_data.label.value_counts().keys())\n",
    "tmp_data['Count'] = list(audio_data.label.value_counts())\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax = sns.barplot(x=\"Emotion\", y='Count', color='#FF5733', data=tmp_data)\n",
    "ax.set_title(\"Data Distribution\")\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l46b8jZvHgvm"
   },
   "outputs": [],
   "source": [
    "X = new_labeled_data.drop(['label'], axis=1)\n",
    "y = new_labeled_data.label\n",
    "X_Stratified = StratifiedShuffleSplit(1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in X_Stratified.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "x_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "x_test_cnn = np.expand_dims(X_test, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423059,
     "status": "ok",
     "timestamp": 1586675635830,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "KlcBFw-FcOrS",
    "outputId": "13d06002-4df1-4210-8956-abc18b157d4c"
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "x_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "x_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labeled_data=pd.read_csv('./data2.csv')\n",
    "X = new_labeled_data.drop(['label'], axis=1)\n",
    "y = new_labeled_data.label\n",
    "X_Stratified = StratifiedShuffleSplit(1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in X_Stratified.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "scaler_filename = \"scaler.save\"\n",
    "joblib.dump(scaler, scaler_filename) \n",
    "\n",
    "\n",
    "\n",
    "x_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "x_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "x_train_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train[0],y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_cnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L36K4xuq7sxU"
   },
   "outputs": [],
   "source": [
    "#Setup Keras util functions\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    f_score = 2 * (p * r) / (p + r + K.epsilon())\n",
    "    return f_score\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1423055,
     "status": "ok",
     "timestamp": 1586675635843,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "6Ne-432DOYzS",
    "outputId": "0194d0db-ef3e-4d0c-8269-bfe9ebd8e78a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "# Edit according to target class no.\n",
    "model.add(Dense(16))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ysiGtz4MOrAD"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1447168,
     "status": "ok",
     "timestamp": 1586675659968,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "4qhq0y9FmvWf",
    "outputId": "11cff470-1fff-4e42-a1de-103ffa3da9b6"
   },
   "outputs": [],
   "source": [
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.01)\n",
    "mcp_save = ModelCheckpoint('./CNN4.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "cnnhistory=model.fit(x_train_cnn,y_train, batch_size=60, epochs=200, validation_data=(x_test_cnn, y_test), callbacks=[mcp_save, lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450024,
     "status": "error",
     "timestamp": 1586675662833,
     "user": {
      "displayName": "harshith vuppala",
      "photoUrl": "",
      "userId": "08570984486188309086"
     },
     "user_tz": -330
    },
    "id": "0gVi2TSfmAKj",
    "outputId": "91ed6a75-913e-49bf-ba19-3d7f3e3237fc"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./CNN4.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "##\n",
    "#test_sound=one_sound('---.wav')\n",
    "#a,b,c,d,e=feature_extraction(test_sound)\n",
    "#test_f=stacking 3horizontal (a,b,c,d,e)\n",
    "#loaded_model.predict(test_f)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "preds = loaded_model.predict(x_test_cnn, batch_size=16,\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNn6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.models.load_model('CNn6.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict_classes(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict_classes(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=x_test_cnn[100].reshape(1,193,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.DataFrame(columns=['feature'])\n",
    "audio_path='./sed_data_set/Actor_07/03-01-08-02-01-02-07.wav'\n",
    "mfccs, chroma, mel, contrast, tonnetz = feature_extraction(audio_path)\n",
    "extracted_features= np.hstack([mfccs,chroma, mel, contrast, tonnetz]) \n",
    "#data.loc[i] = [extracted_features]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Data_Extraction_Audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
