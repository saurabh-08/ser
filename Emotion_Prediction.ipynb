{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1878, 193)\n",
      "(470, 193)\n",
      "(1878, 16)\n",
      "(470, 16)\n",
      "WARNING:tensorflow:From /Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Loaded model from disk\n",
      "WARNING:tensorflow:From /Users/saurabh/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf \n",
    "import sklearn\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#%tensorflow_version 1.4 \n",
    "\n",
    "## Package\n",
    "import glob \n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.offline as py\n",
    "#import plotly.tools as tls\n",
    "import seaborn as sns\n",
    "import scipy.io.wavfile\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#py.init_notebook_mode(connected=True)\n",
    "\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping\n",
    "from keras.callbacks import  History, ReduceLROnPlateau, CSVLogger\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "new_labeled_data=pd.read_csv('./data2.csv')\n",
    "X = new_labeled_data.drop(['label'], axis=1)\n",
    "y = new_labeled_data.label\n",
    "X_Stratified = StratifiedShuffleSplit(1, test_size=0.2, random_state=0)\n",
    "for train_index, test_index in X_Stratified.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "lb = LabelEncoder()\n",
    "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
    "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "x_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "x_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "x_train_cnn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(256, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.10))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 8, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(64, 8, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "# Edit according to target class no.\n",
    "model.add(Dense(16))\n",
    "model.add(Activation(tf.nn.softmax))\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.5, decay=0.0, nesterov=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"./CNN3.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "\n",
    "new_model = keras.models.load_model('CNN3.h5')\n",
    "##\n",
    "#test_sound=one_sound('---.wav')\n",
    "#a,b,c,d,e=feature_extraction(test_sound)\n",
    "#test_f=stacking horizontal (a,b,c,d,e)\n",
    "#loaded_model.predict(test_f)\n",
    "\n",
    "\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "#loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#score = loaded_model.evaluate(x_test_cnn, y_test, verbose=0)\n",
    "#print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "#preds = loaded_model.predict(x_test_cnn, batch_size=16,\n",
    "#                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    if X.ndim > 1:\n",
    "        X = X[:,0]\n",
    "    X = X.T\n",
    "    \n",
    "    # Get features   \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0) #40 values\n",
    "    #zcr = np.mean(librosa.feature.zero_crossing_rate)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T, axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T, axis=0) #tonal centroid features\n",
    "    \n",
    "    ##Return computed features\n",
    "    return mfccs, chroma, mel, contrast, tonnetz\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.DataFrame(columns=['feature'])\n",
    "audio_path='./sed_data_set/Actor_01/03-01-01-01-02-01-01.wav'\n",
    "mfccs, chroma, mel, contrast, tonnetz = feature_extraction(audio_path)\n",
    "extracted_features= np.hstack([mfccs,chroma, mel, contrast, tonnetz]) \n",
    "extracted_features_reshaped=extracted_features.reshape(1,193)\n",
    "\n",
    "#from sklearn.externals \n",
    "#import joblib\n",
    "#scaler = joblib.load(\"scaler.save\") \n",
    "extracted_features=scaler.transform(extracted_features_reshaped)\n",
    "extracted_features_n=extracted_features.reshape(1,193,1)\n",
    "new_model.predict_classes(extracted_features_n)\n",
    "#print(extracted_features_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female_angry', 'female_calm', 'female_disgust', 'female_fearful',\n",
       "       'female_happy', 'female_neutral', 'female_sad', 'female_surprised',\n",
       "       'male_angry', 'male_calm', 'male_disgust', 'male_fearful',\n",
       "       'male_happy', 'male_neutral', 'male_sad', 'male_surprised'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform([0, 1, 2,3,4,5,6,7,8,9,10,11,12,13,14,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
